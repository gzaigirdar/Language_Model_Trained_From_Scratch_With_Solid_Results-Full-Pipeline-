{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b601cdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gz/Documents/Final_version_SLM/.llm_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset,load_from_disk,concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ccf232b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1000000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = load_dataset(\"starhopp3r/TinyChat\")\n",
    "# %%\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa0eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset['train'].select(range(12000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d060c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)\n",
    "pairs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c64ab5",
   "metadata": {},
   "source": [
    "Utility  Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cec121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = re.findall(r\"\\w+(?:'\\w+)*|[^\\w\\s]\", text)\n",
    "    tokens = \" \".join(tokens)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_func(batch, tokenizer,clean_text):\n",
    "    texts = []\n",
    "    for text in batch[\"text\"]:\n",
    "        parts = re.split(r\"\\[/?INST\\]\", text)\n",
    "\n",
    "        dialogue = [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "        for index in range(len(dialogue)-1):\n",
    "            prompt = dialogue[index]\n",
    "            response = dialogue[index+1]\n",
    "            \n",
    "          \n",
    "            texts.append(f\"{tokenizer.bos_token} <user> {clean_text(prompt)} {tokenizer.eos_token} <bot> {clean_text(response)} {tokenizer.eos_token}\")\n",
    "\n",
    "    tokens = tokenizer(texts, padding=False, truncation=False, return_attention_mask=False,add_special_tokens=False)\n",
    "\n",
    "   \n",
    "    input_ids = [list(ids) for ids in tokens[\"input_ids\"]]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"raw_text\": texts\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "# load the saved tokenizer \n",
    "tokenizer_path = '/home/gz/Documents/Full Pipeline(LLM)/Saved_tokenizer/t5_Tokinzer'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path,use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894cbf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 12000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366eac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.map(\n",
    "    lambda batch: preprocess_func(batch, tokenizer,clean_text),\n",
    "    batched=True,\n",
    "    batch_size=800,\n",
    "    num_proc=6,\n",
    "    remove_columns=dataset.column_names\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0629e6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67177fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> <user> would you like to talk about what is making you feel sad today <end> <bot> i think it helps to share feelings and stem them before they grow . <end>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[10001]['raw_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1257fc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e79d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename_column('raw_text','text_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27624a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/gz/Documents/Full Pipeline(LLM)/Saved_Data/processedDataset'\n",
    "dataset_2 = load_from_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bc025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'text_sample'],\n",
       "    num_rows: 104161\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ecd95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104161"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ea7b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'text_sample'],\n",
       "    num_rows: 104161\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54594c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53ff7ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> <user> what do you need when you see a blue flag during the race ? <end> <bot> allow the leader to overtake . <end>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2[98001]['text_sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1889212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'text_sample'],\n",
       "    num_rows: 92613\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00aed3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_dataset =  concatenate_datasets([dataset_2,ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e09f785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'text_sample'],\n",
       "    num_rows: 196774\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d684f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [32101, 32103, 497, 3, 6, 3, 354, 603, 3, 6, 149, 81, 352, 21, 3, 9, 360, 36, 277, 227, 2634, 3, 58, 32100, 32104, 25, 214, 24, 19, 24873, 68, 19, 310, 59, 207, 21, 69, 4639, 3, 5, 32100], 'text_sample': '<start> <user> say , jim , how about going for a few beers after dinner ? <end> <bot> you know that is tempting but is really not good for our fitness . <end>'}\n"
     ]
    }
   ],
   "source": [
    "for sample in combine_dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55983527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 12000\n",
      "Average tokens per sequence: 43.7\n",
      "Minimum tokens: 11\n",
      "Maximum tokens: 413\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lengths = [len(row['input_ids']) for row in combine_dataset]\n",
    "\n",
    "# Compute stats\n",
    "avg_len = sum(lengths) / len(lengths)\n",
    "min_len = min(lengths)\n",
    "max_len = max(lengths)\n",
    "\n",
    "print(f\"Number of sequences: {len(dataset)}\")\n",
    "print(f\"Average tokens per sequence: {avg_len:.1f}\")\n",
    "print(f\"Minimum tokens: {min_len}\")\n",
    "print(f\"Maximum tokens: {max_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c15a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 196774/196774 [00:00<00:00, 2081554.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "processed_path = '/home/gz/Documents/Full Pipeline(LLM)/Saved_Data/Combineed_Pairs_Dataset'\n",
    "\n",
    "combine_dataset.save_to_disk(processed_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
